# ğŸ§  Text Classification, Sentiment Analysis & Topic Modeling with NLP

Ce projet propose une approche complÃ¨te de **text mining** basÃ©e sur un jeu de donnÃ©es de fake news. Il combine plusieurs techniques du **traitement automatique du langage naturel (NLP)** pour :

- Nettoyer les textes
- Vectoriser via TF-IDF
- Classifier les articles (Fake vs Factual)
- Analyser les sentiments
- Extraire les sujets dominants via le Topic Modeling

---

## ğŸ“Œ Objectifs

- Appliquer un pipeline NLP sur des articles de presse
- PrÃ©dire si un article est une fake news ou une information factuelle
- Visualiser les rÃ©sultats (accuracy, matrice de confusion, nuages de mots)
- Comprendre le sentiment global des textes
- Explorer les thÃ¨mes dominants dans les articles

---

## ğŸ§° Technologies utilisÃ©es

| Outil/BibliothÃ¨que | Description |
|--------------------|-------------|
| `pandas`           | Chargement et manipulation des donnÃ©es |
| `matplotlib/seaborn` | Visualisations |
| `nltk`, `spacy`    | NLP : tokenisation, stopwords, lemmatisation |
| `scikit-learn`     | Classification, TF-IDF, Ã©valuation |
| `gensim`           | ModÃ©lisation de sujets (LDA, LSI) |
| `vaderSentiment`   | Analyse de sentiment (rule-based) |

---

## ğŸ“‚ Structure du projet


---

## ğŸ“Š RÃ©sultats ClÃ©s

- PrÃ©cision des modÃ¨les de classification : **Ã  complÃ©ter** (`accuracy_score`)
- RÃ©partition Ã©quilibrÃ©e ou dÃ©sÃ©quilibrÃ©e des classes visualisÃ©e
- RÃ©sultats de sentiment pour chaque article (positif, neutre, nÃ©gatif)
- Topics extraits automatiquement avec LDA/LSI

---

## ğŸ§ª Techniques NLP appliquÃ©es

### ğŸ”¹ PrÃ©traitement

- Nettoyage (regex, suppression des chiffres, ponctuation)
- Tokenisation : avec `nltk` & `spaCy`
- Stopwords removal : via `nltk`
- Lemmatisation : `WordNetLemmatizer` & `spaCy`

### ğŸ”¹ Vectorisation

- `TfidfVectorizer` : transforme les mots en vecteurs numÃ©riques pondÃ©rÃ©s par frÃ©quence inverse

### ğŸ”¹ Classification

- ModÃ¨les utilisÃ©s : 
  - `LogisticRegression`
  - `SGDClassifier`
- Ã‰valuation : 
  - `accuracy_score`
  - `classification_report`

### ğŸ”¹ Analyse de sentiment

- Utilisation de `VADER SentimentIntensityAnalyzer` pour obtenir un score de sentiment par document.

### ğŸ”¹ ModÃ©lisation de sujets (Topic Modeling)

- `gensim.models.LsiModel`, `LdaModel`
- Extraction automatique des sujets dominants dans le corpus

---

## ğŸš€ Lancer le projet

### 1. Installation
Cloner le repo :

git clone https://github.com/votre-utilisateur/text_classification.git
cd text_classification
Installer les dÃ©pendances :

pip install -r requirements.txt

2. Lancer le notebook

jupyter notebook Text_classification.ipynb

ğŸ” Jeu de DonnÃ©es
Nom : fake_news_data.csv

Colonnes principales :

text : contenu textuel de lâ€™article

fake_or_factual : Ã©tiquette de vÃ©ritÃ©

NB : Le fichier CSV doit Ãªtre placÃ© dans le mÃªme dossier que le notebook.

ğŸ“ˆ Visualisations proposÃ©es
RÃ©partition des classes (bar chart)

Matrice de confusion

Score de sentiment

Top mots TF-IDF

Sujets par LDA/LSI

ğŸ“Œ Ã€ venir
AmÃ©lioration du modÃ¨le avec XGBoost, BERT

Export en API REST (Flask/FastAPI)

Dashboard interactif (Streamlit)

ğŸ“š Ressources utiles
Scikit-learn TF-IDF

NLTK Documentation

VADER Sentiment

Gensim Topic Modeling

ğŸ‘¨â€ğŸ’» Auteur
Chouaib Khomalli
Master 1 â€“ IngÃ©nierie des SystÃ¨mes Intelligents - IA
ğŸ“ Casablanca, Maroc
